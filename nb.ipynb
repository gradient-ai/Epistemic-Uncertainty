{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Epistemic Uncertainty\n",
    "\n",
    "## Setup\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as Datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "from torchvision.utils import make_grid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "  print('Running on the GPU')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Running on the CPU')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Training Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  loading training data\n",
    "training_set = Datasets.MNIST(root='./', download=True,\n",
    "                              transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                            transforms.Resize((32, 32)),\n",
    "                                                            transforms.Normalize(0.137, 0.3081)]))\n",
    "\n",
    "#  loading validation data\n",
    "validation_set = Datasets.MNIST(root='./', download=True, train=False,\n",
    "                                transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                              transforms.Resize((32, 32)),\n",
    "                                                              transforms.Normalize(0.137, 0.3081)]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LeNet5 model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class LeNet5_Dropout(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "    self.dropout = nn.Dropout2d()\n",
    "    self.pool1 = nn.AvgPool2d(2)\n",
    "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "    self.pool2 = nn.AvgPool2d(2)\n",
    "    self.linear1 = nn.Linear(5*5*16, 120)\n",
    "    self.linear2 = nn.Linear(120, 84)\n",
    "    self.linear3 = nn. Linear(84, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, 1, 32, 32)\n",
    "\n",
    "    #----------\n",
    "    # LAYER 1\n",
    "    #----------\n",
    "    output_1 = self.conv1(x)\n",
    "    output_1 = torch.tanh(output_1)\n",
    "    output_1 = self.dropout(output_1)\n",
    "    output_1 = self.pool1(output_1)\n",
    "    \n",
    "    #----------\n",
    "    # LAYER 2\n",
    "    #----------\n",
    "    output_2 = self.conv2(output_1)\n",
    "    output_2 = torch.tanh(output_2)\n",
    "    output_2 = self.dropout(output_2)\n",
    "    output_2 = self.pool2(output_2)\n",
    "    \n",
    "    #----------\n",
    "    # FLATTEN\n",
    "    #----------\n",
    "    output_2 = output_2.view(-1, 5*5*16)\n",
    "\n",
    "    #----------\n",
    "    # LAYER 3\n",
    "    #----------\n",
    "    output_3 = self.linear1(output_2)\n",
    "    output_3 = torch.tanh(output_3)\n",
    "    \n",
    "    #----------\n",
    "    # LAYER 4\n",
    "    #----------\n",
    "    output_4 = self.linear2(output_3)\n",
    "    output_4 = torch.tanh(output_4)\n",
    "    \n",
    "    #-------------\n",
    "    # OUTPUT LAYER\n",
    "    #-------------\n",
    "    output_5 = self.linear3(output_4)\n",
    "    return(F.softmax(output_5, dim=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training, Validation and Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ConvolutionalNeuralNet():\n",
    "  def __init__(self, network):\n",
    "    self.network = network.to(device)\n",
    "    self.optimizer = torch.optim.Adam(self.network.parameters(), lr=1e-3)\n",
    "\n",
    "  def train(self, loss_function, epochs, batch_size, \n",
    "            training_set, validation_set):\n",
    "    \n",
    "    #  creating log\n",
    "    log_dict = {\n",
    "        'training_loss_per_batch': [],\n",
    "        'validation_loss_per_batch': [],\n",
    "        'training_accuracy_per_epoch': [],\n",
    "        'training_recall_per_epoch': [],\n",
    "        'training_precision_per_epoch': [],\n",
    "        'validation_accuracy_per_epoch': [],\n",
    "        'validation_recall_per_epoch': [],\n",
    "        'validation_precision_per_epoch': []\n",
    "    } \n",
    "\n",
    "    #  defining weight initialization function\n",
    "    def init_weights(module):\n",
    "      if isinstance(module, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        module.bias.data.fill_(0.01)\n",
    "      elif isinstance(module, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        module.bias.data.fill_(0.01)\n",
    "\n",
    "    #  defining accuracy function\n",
    "    def accuracy(network, dataloader):\n",
    "      network.eval()\n",
    "      \n",
    "      all_predictions = []\n",
    "      all_labels = []\n",
    "\n",
    "      #  computing accuracy\n",
    "      total_correct = 0\n",
    "      total_instances = 0\n",
    "      for images, labels in tqdm(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        all_labels.extend(labels)\n",
    "        predictions = torch.argmax(network(images), dim=1)\n",
    "        all_predictions.extend(predictions)\n",
    "        correct_predictions = sum(predictions==labels).item()\n",
    "        total_correct+=correct_predictions\n",
    "        total_instances+=len(images)\n",
    "      accuracy = round(total_correct/total_instances, 3)\n",
    "\n",
    "      #  computing recall and precision\n",
    "      true_positives = 0\n",
    "      false_negatives = 0\n",
    "      false_positives = 0\n",
    "      for idx in range(len(all_predictions)):\n",
    "        if all_predictions[idx].item()==1 and  all_labels[idx].item()==1:\n",
    "          true_positives+=1\n",
    "        elif all_predictions[idx].item()==0 and all_labels[idx].item()==1:\n",
    "          false_negatives+=1\n",
    "        elif all_predictions[idx].item()==1 and all_labels[idx].item()==0:\n",
    "          false_positives+=1\n",
    "      try:\n",
    "        recall = round(true_positives/(true_positives + false_negatives), 3)\n",
    "      except ZeroDivisionError:\n",
    "        recall = 0.0\n",
    "      try:\n",
    "        precision = round(true_positives/(true_positives + false_positives), 3)\n",
    "      except ZeroDivisionError:\n",
    "        precision = 0.0\n",
    "      return accuracy, recall, precision\n",
    "\n",
    "    #  initializing network weights\n",
    "    self.network.apply(init_weights)\n",
    "\n",
    "    #  creating dataloaders\n",
    "    train_loader = DataLoader(training_set, batch_size)\n",
    "    val_loader = DataLoader(validation_set, batch_size)\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "      print(f'Epoch {epoch+1}/{epochs}')\n",
    "      train_losses = []\n",
    "\n",
    "      #  training\n",
    "      #  setting convnet to training mode\n",
    "      self.network.train()\n",
    "      print('training...')\n",
    "      for images, labels in tqdm(train_loader):\n",
    "        #  sending data to device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        #  resetting gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        #  making predictions\n",
    "        predictions = self.network(images)\n",
    "        #  computing loss\n",
    "        loss = loss_function(predictions, labels)\n",
    "        log_dict['training_loss_per_batch'].append(loss.item())\n",
    "        train_losses.append(loss.item())\n",
    "        #  computing gradients\n",
    "        loss.backward()\n",
    "        #  updating weights\n",
    "        self.optimizer.step()\n",
    "      with torch.no_grad():\n",
    "        print('deriving training accuracy...')\n",
    "        #  computing training accuracy\n",
    "        train_accuracy, train_recall, train_precision = accuracy(self.network, train_loader)\n",
    "        log_dict['training_accuracy_per_epoch'].append(train_accuracy)\n",
    "        log_dict['training_recall_per_epoch'].append(train_recall)\n",
    "        log_dict['training_precision_per_epoch'].append(train_precision)\n",
    "\n",
    "      #  validation\n",
    "      print('validating...')\n",
    "      val_losses = []\n",
    "\n",
    "      #  setting convnet to evaluation mode\n",
    "      self.network.eval()\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "          #  sending data to device\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          #  making predictions\n",
    "          predictions = self.network(images)\n",
    "          #  computing loss\n",
    "          val_loss = loss_function(predictions, labels)\n",
    "          log_dict['validation_loss_per_batch'].append(val_loss.item())\n",
    "          val_losses.append(val_loss.item())\n",
    "        #  computing accuracy\n",
    "        print('deriving validation accuracy...')\n",
    "        val_accuracy, val_recall, val_precision = accuracy(self.network, val_loader)\n",
    "        log_dict['validation_accuracy_per_epoch'].append(val_accuracy)\n",
    "        log_dict['validation_recall_per_epoch'].append(val_recall)\n",
    "        log_dict['validation_precision_per_epoch'].append(val_precision)\n",
    "\n",
    "      train_losses = np.array(train_losses).mean()\n",
    "      val_losses = np.array(val_losses).mean()\n",
    "\n",
    "      print(f'training_loss: {round(train_losses, 4)}  training_accuracy: '+\n",
    "      f'{train_accuracy}  training_recall: {train_recall}  training_precision: {train_precision} *~* validation_loss: {round(val_losses, 4)} '+  \n",
    "      f'validation_accuracy: {val_accuracy}  validation_recall: {val_recall}  validation_precision: {val_precision}\\n')\n",
    "      \n",
    "    return log_dict\n",
    "\n",
    "  def predict(self, x, eval=True):\n",
    "    if eval:\n",
    "      with torch.no_grad():\n",
    "        return self.network(x)\n",
    "    else:\n",
    "      with torch.no_grad():\n",
    "        self.network.train()\n",
    "        return self.network(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = ConvolutionalNeuralNet(LeNet5_Dropout())\n",
    "\n",
    "#  training model and deriving metrics\n",
    "log_dict = model.train(nn.CrossEntropyLoss(), epochs=10, batch_size=64, \n",
    "                           training_set=training_set, validation_set=validation_set)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"assets/epist_accuracy-1.png\"\n",
    "     alt=\"sample image\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bayesian Inference"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  extracting two images from the validation set\n",
    "image_1 = validation_set[61]\n",
    "image_2 = validation_set[591]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def epistemic_check(model, image, model_number=20):\n",
    "  \"\"\"\n",
    "  This model returns a count plot of model classifications\n",
    "  \"\"\"\n",
    "  confidence = []\n",
    "\n",
    "  for i in range(model_number):\n",
    "    confidence.append(torch.argmax(F.softmax(model.predict(image.to(device), \n",
    "                                                           eval=False), dim=1)).item())\n",
    "\n",
    "  return sns.countplot(x=confidence)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epistemic_check(model, image_1[0], 100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "epistemic_check(model, image_2[0], 100)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}